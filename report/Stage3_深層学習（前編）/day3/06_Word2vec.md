【要点まとめ】  
RNNでは、可変長の文字列をNNに与えることはできない。  
→固定長で単語を表現する必要がある。  
word2vecでは学習データからボキャブラリを作成（分散表現ベクトルに変換）する。  
これにより、大規模データの分散表現による学習が現実的な計算速度とメモリで実現可能とした。  
  
【実装演習】  
ソースコードが無いため省略します  
  
【実装演習考察】  
ソースコードが無いため省略します  
  
【自己学習】  
※参考資料：ゼロから作るDeepLearning②  
word2vecには2つのアルゴリズムがある。  
* CBOW：コンテクスト（周辺情報）からターゲットを予測する。
* skip-gram：CBOWの逆で、ターゲットからコンテクストを予測する。
skip-gramのほうが良い結果が得られるとされているが、学習コストが大きい。  
