【要点まとめ】

主成分分析
  ・統計学上のデータ解析手法のひとつで、データの次元を削減するために用いられる。
  ・見通しの良い1～3程度の次元まで削減することが多い。
  ・データの散らばり（分散）が最大になるように次元削減を行う。
  ※グラフにしたときに射影軸が右肩上がりになる（分散が大きい）


【実装演習】
乳がんの診断での次元数削減を検証する
```
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA

data = pd.read_csv('./data/cancer.csv')
```
```
# radius_meanからnoname手前のfractal_dimension_worstまで３０次元を使用する
X = data.loc[:, "radius_mean":"fractal_dimension_worst"]
y = data['diagnosis'] = data['diagnosis'].map({'B' : 0, 'M' : 1}).astype(int)
```
```
# テストデータと訓練データに分割
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 5)
```
```
# 学習
model = LogisticRegression(max_iter=2000)
model.fit(X_train, y_train)
```
```
# 30次元でのスコアを算出
dimention_30 = model.score(X_test, y_test)
```
```
# 次元数を2まで削減してみる
pca = PCA(n_components=2)
X_train2 = pca.fit_transform(X_train)
X_test2 = pca.fit_transform(X_test)
```
```
# 学習
model.fit(X_train2, y_train)
```
```
# 2次元でのスコアを算出
dimention_2 = model.score(X_test2, y_test)
```
```
dimention_30
```
```
0.9790209790209791
```
```
dimention_2
```
```
0.8811188811188811
```

【考察】
30次元では97%のスコア、2次元まで削減すると88%のスコアとなった。
9%の違いが大きく響くかは要件次第かもしれないが、大幅に次元を削減しても問題ないケースがあることがわかった。